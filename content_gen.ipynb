{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaga-bello/150_challenges/blob/main/content_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxzrqiVEdXEw"
      },
      "outputs": [],
      "source": [
        "# maj de pip\n",
        "! pip install --upgrade pip\n",
        "\n",
        "# Installation de la bibliothèque openai\n",
        "! pip install openai\n",
        "\n",
        "# Installation de la bibliothèque GIS\n",
        "! pip install Google-Images-Search\n",
        "n\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import concurrent.futures\n",
        "import urllib.parse\n",
        "import re\n",
        "import random\n",
        "import requests\n",
        "import time\n",
        "import base64\n",
        "import json\n",
        "from urllib import parse as urlparse\n",
        "from PIL import Image, ImageColor, ImageEnhance\n",
        "from io import BytesIO\n",
        "from secrets import token_hex\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from google_images_search import GoogleImagesSearch\n",
        "from datetime import datetime, timedelta\n",
        "import glob\n",
        "\n",
        "get_file = lambda: (glob.glob('*.xlsx') + glob.glob('*.xls'))[0]\n",
        "get_file()\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "logs = {\n",
        "    'wpUN': 'khjgkh5hgkhjg',\n",
        "    'wpPW': '22hK JiIR vVjG Sec9 4J0z ondB',\n",
        "    'wpDomain': 'hypervirtual.fr',\n",
        "    'API_key' : \"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\",\n",
        "    'xls_file' : get_file()\n",
        "}\n",
        "\n",
        "# Initialisation d'une session requests pour la navigation web\n",
        "session = requests.Session()\n",
        "openai.api_key = logs['API_key']\n",
        "\n",
        "# Headers pour simuler une navigation avec un navigateur web\n",
        "headers = {\n",
        "    'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'\n",
        "}\n",
        "session.headers.update(headers)\n",
        "\n",
        "def get_cat_table(casino):\n",
        "  def get_cat_id(cats, cat):\n",
        "\n",
        "    hed = header(logs['wpUN'],logs['wpPW'])\n",
        "    data = {'name': cat}\n",
        "\n",
        "    responce = session.post(f\"http://{logs['wpDomain']}/wp-json/wp/v2/categories\", headers = hed, json = data)\n",
        "\n",
        "    if responce.status_code == 201:\n",
        "      id = (responce.json()['id'])\n",
        "    elif responce.status_code == 400:\n",
        "      id = (responce.json()['data']['term_id'])\n",
        "    else:\n",
        "      print(\"There was an error with the category\")\n",
        "\n",
        "    cats.append(id)\n",
        "\n",
        "  cat_ids = []\n",
        "  # df = pd.read_excel(logs['xls_file'])\n",
        "  # df = df.loc[df['PAA Title'].str.contains(rf'\\b{casino}\\b')].iloc[0]\n",
        "  cats = \"Tech\" # df['Parent']\n",
        "\n",
        "  get_cat_id(cat_ids, cats)\n",
        "\n",
        "  return cat_ids\n",
        "\n",
        "def get_img_id(casino):\n",
        "  def imgPost(data):\n",
        "    title = 'pexels-photo-15792909'\n",
        "    headers = {\"Content-Type\": \"image/jpeg\", \"Accept\": \"application/json\", 'Content-Disposition': f\"attachment; filename={title}-{token_hex(20)}.jpg\",}\n",
        "    auth = (logs['wpUN'], logs['wpPW'])\n",
        "    return session.post(url = f'http://{logs[\"wpDomain\"]}/wp-json/wp/v2/media', auth=auth, headers=headers, data=data).json()\n",
        "\n",
        "  cx=\"82e51024fa94949a3\"\n",
        "  api = \"AIzaSyC9_3tM2GhhQcKQMmyXlbIJqUwdecdfBI0\"\n",
        "\n",
        "  gis = GoogleImagesSearch(api, cx)\n",
        "  gis.search({'q': casino, 'num': 1})\n",
        "  image_urls = [result.url for result in gis.results()]\n",
        "\n",
        "  data = requests.get(image_urls[0]).content\n",
        "  image = Image.open(BytesIO(data))\n",
        "  enhancer = ImageEnhance.Color(image)\n",
        "  fI = enhancer.enhance(random.uniform(.5,.5))\n",
        "  imgData = BytesIO()\n",
        "  fI.save(imgData, format='JPEG')\n",
        "  img_data_value = imgData.getvalue()\n",
        "\n",
        "  return imgPost(img_data_value)['id']\n",
        "\n",
        "# Fonction pour récupérer un lien Youtube aléatoire en fonction d'une question donnée\n",
        "def get_random_yt_link(question):\n",
        "  # URL de recherche Youtube\n",
        "  yt_url = 'https://www.youtube.com/results?search_query='\n",
        "\n",
        "  # Encodage de la requête pour l'URL\n",
        "  req = question\n",
        "  parse_req = urlparse.quote_plus(req)\n",
        "\n",
        "  # Construction de l'URL de recherche Youtube\n",
        "  yt_req = yt_url + parse_req\n",
        "\n",
        "  # Envoi de la requête à Youtube et récupération du contenu de la page\n",
        "  response = session.get(yt_req)\n",
        "  text = response.text\n",
        "\n",
        "  # Recherche des liens de vidéos Youtube dans le contenu de la page\n",
        "  pattern = r'\"(\\/watch\\?v\\=.*?)\\\"'\n",
        "  match = re.findall(pattern, text)\n",
        "\n",
        "  # Retourne un lien Youtube aléatoire parmi les 5 premiers liens trouvés\n",
        "  return random.choice(match[:5])\n",
        "\n",
        "def get_headers(kw):\n",
        "  page = requests.get(f'https://www.google.fr/search?q={urlparse.quote_plus(kw)}&gl=fr&hl=fr&gws_rd=cr&pws=0')\n",
        "  bs = BeautifulSoup(page.text, 'lxml')\n",
        "\n",
        "  a_list = bs.find_all('a')\n",
        "  a_list = [a.get('href') for a in a_list if ('https' in a.get('href') or 'http' in a.get('href')) and 'google' not in a.get('href')]\n",
        "  pattern = r\"https?://[^&]+\"\n",
        "\n",
        "  striped_url = []\n",
        "  for a in a_list:\n",
        "    match = re.search(pattern, a)\n",
        "    if '%' not in match.group() and 'forum' not in match.group():\n",
        "      striped_url.append(match.group())\n",
        "\n",
        "  headers = []\n",
        "  for url in striped_url:\n",
        "    page = requests.get(url)\n",
        "    bs = BeautifulSoup(page.text, 'lxml')\n",
        "\n",
        "    try:\n",
        "      header_elements = bs.find('article').find_all(['h2', 'h3'])\n",
        "\n",
        "      # Iterate over the header elements and extract their text\n",
        "      for header in header_elements:\n",
        "          headers.append(str(header))\n",
        "      headers = [h2.replace('\\xa0', '') for h2 in headers if '\\n' not in h2]\n",
        "      if headers:\n",
        "        break\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    if headers:\n",
        "      break\n",
        "\n",
        "  heads = []\n",
        "  for hn in headers:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[{\"role\": \"user\", \"content\": f\"je veux que tu réecrivent ENTETE: {hn}, sans ajouter de texte\"}]\n",
        "    )\n",
        "\n",
        "    # Récupération de l'article HTML généré\n",
        "    heads.append(response['choices'][0]['message']['content'])\n",
        "\n",
        "  # return entete_final.replace(\"\\n\", \"\")\n",
        "  return heads\n",
        "\n",
        "def get_title(question):\n",
        "  openai.api_key = logs['API_key']\n",
        "  ai_title = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt=f\"génère moi un titre pour un article sur '{question}' \",\n",
        "      temperature=0.7,\n",
        "      max_tokens=2560,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # Récupération de l'article HTML généré\n",
        "  ai_title = ai_title['choices'][0]['text']\n",
        "  return ai_title.strip().replace(\"»\", \"\").replace(\"«\", \"\").replace('\"', \"\")\n",
        "\n",
        "def faq(kw):\n",
        "  def get_qsn(question):\n",
        "    answer = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",messages=[{\"role\": \"user\", \"content\": f\"Réponds la questions suivant en 50 mots maximum {question}\"}])['choices'][0]['message']['content']\n",
        "    faq_div = fr\"\"\"\n",
        "      <div itemscope=\"\" itemprop=\"\" itemtype=\"https://schema.org/Question\" class=\"faq-question\">\n",
        "          <h3 itemprop=\"name\" class='\"faq-q\"'>{question}</h3>\n",
        "          <div itemscope=\"\" itemprop=\"acceptedAnswer\" itemtype=\"https://schema.org/Answer\">\n",
        "              <p itemprop=\"text\" class=\"faq-a\">{answer}</p>\n",
        "          </div>\n",
        "      </div>\"\"\"\n",
        "    return faq_div\n",
        "\n",
        "  page = session.get(f\"https://www.google.fr/search?q={urlparse.quote_plus(kw)}&gl=fr&hl=fr&gws_rd=cr&pws=0\")\n",
        "  bs = BeautifulSoup(page.text, 'lxml')\n",
        "  questions = [q.text for q in bs.select(\"span.CSkcDe\")]\n",
        "\n",
        "  main_entity = []\n",
        "\n",
        "  for q in questions:\n",
        "    main_entity.append(get_qsn(q))\n",
        "\n",
        "  faq_html = fr\"\"\"<h2>FAQ</h2><div class='schema-faq-code' itemscope='' itemtype='https://schema.org/FAQPage'>{\" \".join(main_entity)}</div>\"\"\"\n",
        "\n",
        "  return faq_html\n",
        "\n",
        "# Fonction pour générer un article HTML à partir d'une question\n",
        "def create_content(question):\n",
        "\n",
        "  data = {}\n",
        "  # Clé API OpenAI\n",
        "  openai.api_key = logs['API_key']\n",
        "\n",
        "  mots_cle = get_kw_guides(question)\n",
        "\n",
        "  p_title = get_title(question)\n",
        "\n",
        "  entete = get_headers(question)\n",
        "\n",
        "  # Génération de l'article HTML avec OpenAI\n",
        "  # inserer une boucle qui vas demander un article si le code est différent de 200\n",
        "  response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-16k\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"La rédaction doit etre en langage HTML, explique chaque paragraphes en détail\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Tu est un rédacteur experimenté, rédiges moi  en language HTML un article sur {question}. je veux une introduction de 50 mots, base toi sur les entêtes suivant pour la structure de l'article {entete}, pour chaque titres ecris 2 paragraphes minimum, ne met pas de title. voici une liste importante de mots clé {mots_cle} en redigeant l'article met les mots-clés en gras en utilisant la balise html <strong>. Écris comme un humain en soyant le plus explicite possible et évite les répétitions en utilisant un maximum de synonymes, n'hésite pas a rajouter des listes a puce pour détailler certaines section. Utilise le mot {random.choices(['Les prochaines étapes', 'Réflexions finales', 'Synthèse des résultats', 'Les perspectives futures', 'Les leçons à retenir', 'Récapitulatif des points clés', 'En conclusion'])} pour conclure ton article.\"}\n",
        "        ]\n",
        "  )\n",
        "\n",
        "  # Récupération de l'article HTML généré\n",
        "  html = response['choices'][0]['message']['content']\n",
        "  html = html.strip().replace(\"\\n </strong>\\n \", \"</strong>\").replace(\"\\n <strong>\\n \", \"<strong>\")\n",
        "\n",
        "  # Récupération d'un lien Youtube aléatoire en fonction de la question donnée\n",
        "  result = get_random_yt_link(question)\n",
        "  yt_id = result.split('v=')[-1]\n",
        "  vid_iframe = f'<iframe width=\"100%\" height=\"450px\" src=\"https://www.youtube.com/embed/{yt_id}?amp;controls=1&amp;autoplay=0&amp;mute=1&amp;modestbranding=1&amp;rel=0&amp;loop=0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\"></iframe>'\n",
        "\n",
        "  # Concaténation des éléments générés pour former le contenu final de l'article HTML\n",
        "  cat_table = get_cat_table(question)\n",
        "  cat_ids = cat_table\n",
        "\n",
        "  faq_html = faq(question)\n",
        "\n",
        "  # Find the last h2 tag and insert \"my info\" before it\n",
        "  html = html.replace(\"h1\", \"h2\")\n",
        "  soup = BeautifulSoup(str(html), 'lxml')\n",
        "  last_h2_tag = soup.find_all('p')[-5]\n",
        "  new_tag = soup.new_tag('center')\n",
        "  new_tag.string = vid_iframe\n",
        "  last_h2_tag.insert_after(new_tag)\n",
        "  last_p_tag = soup.find_all('p')[-1]\n",
        "  new_tag = soup.new_tag('section')\n",
        "  new_tag.string = str(faq_html)\n",
        "  last_p_tag.insert_after(new_tag)\n",
        "  content = soup.prettify().replace('&lt;', '<').replace('&gt;', '>')\n",
        "\n",
        "  data['content'] = str(content)\n",
        "  data['content'] = data['content'].replace(\"\\n\", \" \")\n",
        "  data['title'] = p_title\n",
        "  data['status'] = 'publish' # ou draft\n",
        "  data['categories'] = cat_ids\n",
        "  try:\n",
        "    data['featured_media'] = get_img_id(question)\n",
        "  except:\n",
        "    data['featured_media'] = None\n",
        "\n",
        "  return   data\n",
        "\n",
        "def header(user, password):\n",
        "  credentials = user + ':' + password\n",
        "  token = base64.b64encode(credentials.encode())\n",
        "  header_json = {'Authorization': 'Basic ' + token.decode('utf-8')}\n",
        "  return header_json\n",
        "\n",
        "def upload_content(post_data):\n",
        "  hed = header(logs['wpUN'],logs['wpPW'])\n",
        "  responce = session.post(f\"http://{logs['wpDomain']}/wp-json/wp/v2/posts\", headers = hed, json = post_data)\n",
        "  return responce\n",
        "\n",
        "def publish_content(title, publish_date):\n",
        "  data = create_content(title)\n",
        "  data['date'] = publish_date\n",
        "  response = upload_content(data)\n",
        "  time.sleep(5)\n",
        "\n",
        "  return response.json()\n",
        "\n",
        "def main():\n",
        "  df = pd.read_excel(logs['xls_file'])\n",
        "  casinos = [i for i in df['Keyword']]\n",
        "\n",
        "  current_date = datetime.strptime(\"2023-09-22T14:23:01\", \"%Y-%m-%dT%H:%M:%S\")\n",
        "  # current_date = datetime.now()\n",
        "  for nom_cas in casinos[54:]:\n",
        "    print(f'Publication de : {nom_cas}')\n",
        "    try:\n",
        "      days_range = random.randint(0,2)\n",
        "      publish_date = current_date + timedelta(days=days_range)\n",
        "      current_date = publish_date\n",
        "      final_date = publish_date.strftime('%Y-%m-%dT%H:%M:%S')\n",
        "      post = publish_content(nom_cas, final_date)\n",
        "      print(f\"{str(casinos.index(nom_cas)+1)}  ID=> {str(post['id'])} URL-> {str(post['link'])} Date -> {final_date}\")\n",
        "    except Exception as error:\n",
        "      print(f'Erreur sur : {nom_cas} => {error}')\n",
        "      pass\n",
        "    # break\n",
        "\n",
        "# start = datetime.now()\n",
        "# main()\n",
        "# end = datetime.now()\n",
        "# print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "P0MHkCYGs5V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goJ5EcqlK8Ab",
        "outputId": "0ff153cb-4673-4f60-e507-1c39311db2e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [201]>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = {\n",
        "    'title' : 'test',\n",
        "    'content' : 'test contnet',\n",
        "    'status' : 'draft',\n",
        "\n",
        "}\n",
        "\n",
        "upload_content(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om08g2L4NH-h",
        "outputId": "8b859718-1330-4503-cc21-3a11c4147121"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [201]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"ou mettre son argent liquide\"\n",
        "content = create_content(question)\n",
        "upload_content(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uynyNTLRQ0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b6be3f57-18cd-4b63-e98d-4506ba5c90fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n      <div itemscope='' itemprop='' itemtype='https://schema.org/Question' class='faq-question'>\\n          <h3 itemprop='name' class='faq-q'>bhhe</h3>\\n          <div itemscope='' itemprop='acceptedAnswer' itemtype='https://schema.org/Answer'>\\n              <p itemprop='text' class='faq-a'>mdns</p>\\n          </div>\\n      </div>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "a1 = \"bhhe\"\n",
        "q1 = \"mdns\"\n",
        "\n",
        "b = fr\"\"\"\n",
        "      <div itemscope='' itemprop='' itemtype='https://schema.org/Question' class='faq-question'>\n",
        "          <h3 itemprop='name' class='faq-q'>{a1}</h3>\n",
        "          <div itemscope='' itemprop='acceptedAnswer' itemtype='https://schema.org/Answer'>\n",
        "              <p itemprop='text' class='faq-a'>{q1}</p>\n",
        "          </div>\n",
        "      </div>\"\"\"\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = [\"dasd\", \"asdfa\",\"sd sd\"]\n",
        "\n",
        "a = fr\"\"\"<h2>FAQ</h2><div class='schema-faq-code' itemscope='' itemtype='https://schema.org/FAQPage'>{\" \".join(b)}</div>\"\"\"\n",
        "str(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B7tUSM0LFN9p",
        "outputId": "83e8d7d6-b916-439a-a19b-0544ba17f963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<h2>FAQ</h2><div class='schema-faq-code' itemscope='' itemtype='https://schema.org/FAQPage'>dasd asdfa sd sd</div>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}